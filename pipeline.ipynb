{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = joblib.load(\"kmeans.pkl\")\n",
    "scaler = joblib.load(\"minmax_scaler.pkl\")\n",
    "svm_model = joblib.load(\"final_model.pkl\")\n",
    "with open(\"dropped_features.pkl\", 'rb') as file: dropped_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    def __init__(self, img):\n",
    "        \"\"\"\n",
    "        Initialize the Preprocessing class with an image.\n",
    "        Args:\n",
    "            img (numpy.ndarray): The image to be processed, assumed to be in grayscale.\n",
    "        \"\"\"\n",
    "        self.img = img  # the image to be processed\n",
    "        self.angles = []  # list to store the angles of text orientations\n",
    "    \n",
    "    def fix_color(self):\n",
    "        \"\"\"\n",
    "        Inverts the image colors if the average color of the border pixels is light.\n",
    "        This is to ensure that the text is darker than the background for better processing.\n",
    "        \"\"\"\n",
    "        # Extract the border pixels\n",
    "        top = self.img[0]\n",
    "        bottom = self.img[-1]\n",
    "        left = self.img[:,0]\n",
    "        right = self.img[:,-1]\n",
    "        \n",
    "        # Calculate the average color of the border pixels\n",
    "        avg = np.mean([np.mean(top), np.mean(bottom), np.mean(left), np.mean(right)])\n",
    "        \n",
    "        # Invert the image colors if the average is light\n",
    "        if avg > 128:\n",
    "            self.img = 255 - self.img\n",
    "\n",
    "    def binarize_image(self):\n",
    "        \"\"\"\n",
    "        Applies median blurring and Otsu's thresholding to binarize the image.\n",
    "        After thresholding, it calls fix_color to ensure proper contrast.\n",
    "        \"\"\"\n",
    "        # Apply median blurring twice to reduce noise\n",
    "        self.img = cv2.medianBlur(self.img, 3)\n",
    "        self.img = cv2.medianBlur(self.img, 3)\n",
    "        \n",
    "        # Apply Otsu's thresholding\n",
    "        _, self.img = cv2.threshold(self.img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Ensure the text is darker than the background\n",
    "        self.fix_color()\n",
    "\n",
    "    def get_rectangle_angles(self, structuring_element_size=20, display_rectangles=False):\n",
    "        \"\"\"\n",
    "        Detects contours in the image and computes the orientation of each contour's minimum area rectangle.\n",
    "        Optionally displays these rectangles overlaid on the image.\n",
    "        Args:\n",
    "            structuring_element_size (int): Size of the structuring element for morphological operations.\n",
    "            display_rectangles (bool): If True, display the image with rectangles drawn around detected contours.\n",
    "        \"\"\"\n",
    "        # Apply morphological closing to make the contours more detectable\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (structuring_element_size, structuring_element_size))\n",
    "        processed = cv2.morphologyEx(self.img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours in the processed image\n",
    "        contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Optional: prepare image for rectangle visualization\n",
    "        if display_rectangles: \n",
    "            color_img = cv2.cvtColor(self.img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Process each detected contour\n",
    "        for contour in contours:\n",
    "            rect = cv2.minAreaRect(contour)  # get the minimum area rectangle\n",
    "            angle = rect[2]  # extract the angle\n",
    "            \n",
    "            # Adjust angle for a consistent representation\n",
    "            if rect[1][0] < rect[1][1]:\n",
    "                angle -= 90\n",
    "            \n",
    "            self.angles.append(angle)\n",
    "\n",
    "            # If displaying rectangles, draw them on the image\n",
    "            if display_rectangles:\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                cv2.drawContours(color_img, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the image with drawn rectangles\n",
    "        if display_rectangles:\n",
    "            plt.imshow(cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB))\n",
    "            plt.show()\n",
    "\n",
    "    def plot_angles_histogram(self):\n",
    "        \"\"\"\n",
    "        Plots a histogram of the angles of text orientations.\n",
    "        This only works if there are angles collected in the self.angles list.\n",
    "        \"\"\"\n",
    "        if self.angles:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(self.angles, bins=30, color='green', alpha=0.7)\n",
    "            plt.title('Distribution of Text Orientations')\n",
    "            plt.xlabel('Angle (degrees)')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    def find_best_angle(self):\n",
    "        \"\"\"\n",
    "        Finds the most common text orientation angle from the histogram of angles.\n",
    "        Returns:\n",
    "            float: The average angle from the most populated bin in the histogram.\n",
    "        \"\"\"\n",
    "        hist, bin_edges = np.histogram(self.angles, bins=30)\n",
    "        max_bin_index = np.argmax(hist)\n",
    "        return np.mean([bin_edges[max_bin_index], bin_edges[max_bin_index + 1]])\n",
    "\n",
    "    def rotate_image(self, angle):\n",
    "        \"\"\"\n",
    "        Rotates the image by a specified angle.\n",
    "        Args:\n",
    "            angle (float): The angle to rotate the image by, in degrees.\n",
    "        \"\"\"\n",
    "        (h, w) = self.img.shape[:2]  # image dimensions\n",
    "        center = (w / 2, h / 2)  # image center\n",
    "\n",
    "        # Compute the rotation matrix for the rotation and the scale\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        \n",
    "        # Apply the rotation to the image\n",
    "        rotated_img = cv2.warpAffine(self.img, M, (w, h))\n",
    "        \n",
    "        # Update the image\n",
    "        self.img = rotated_img\n",
    "\n",
    "    def find_text_region(self, structuring_element_size=150):\n",
    "        \"\"\"\n",
    "        Find the region containing the largest bounding rectangle after applying morphological closing.\n",
    "\n",
    "        Args:\n",
    "            structuring_element_size (int): Size of the structuring element for morphological closing.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The cropped region with the largest bounding rectangle.\n",
    "        \"\"\"\n",
    "        # Apply morphological closing to connect the text regions\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (structuring_element_size, structuring_element_size))\n",
    "        closed_img = cv2.morphologyEx(self.img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours in the closed image\n",
    "        contours, _ = cv2.findContours(closed_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the contour with the largest bounding rectangle\n",
    "        max_area = 0\n",
    "        max_rect = None\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            area = w * h\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                max_rect = (x, y, w, h)\n",
    "\n",
    "        # Crop the region with the largest bounding rectangle\n",
    "        if max_rect is not None:\n",
    "            x, y, w, h = max_rect\n",
    "            return self.img[y:y + h, x:x + w]\n",
    "        else:\n",
    "            return self.img  # Return the whole image if no contours are found\n",
    "\n",
    "\n",
    "    def preprocess_image(self, structuring_element_size=20, display_rectangles=False):\n",
    "        \"\"\"\n",
    "        Executes the full preprocessing pipeline on the image, which includes binarization,\n",
    "        detecting text orientations, finding the best rotation angle, and rotating the image.\n",
    "        Args:\n",
    "            structuring_element_size (int): Size of the kernel for morphological operations.\n",
    "            display_rectangles (bool): Whether to display the rectangles around detected contours.\n",
    "        Returns:\n",
    "            The rotated image.\n",
    "        \"\"\"\n",
    "        self.binarize_image()\n",
    "        self.get_rectangle_angles(structuring_element_size, display_rectangles)\n",
    "        best_angle = self.find_best_angle()\n",
    "        self.rotate_image(best_angle)\n",
    "        self.img = self.find_text_region()\n",
    "        self.binarize_image()\n",
    "        return self.img\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoVW:\n",
    "    def __init__(self):\n",
    "        self.feature_vectors = []\n",
    "\n",
    "    def extract_SIFT_descriptors(self, data):\n",
    "        descriptors = []\n",
    "        sift = cv2.SIFT_create()\n",
    "        for img in data:\n",
    "            img = (255 * img).astype(np.uint8)\n",
    "            if len(img.shape) == 3: \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            kp, desc = sift.detectAndCompute(img, None)\n",
    "            if desc is not None:\n",
    "                descriptors.append(desc)\n",
    "            else:\n",
    "                print(\"No descriptors found for an image.\")\n",
    "        return descriptors\n",
    "    \n",
    "    def extract_BoVW(self, data, k=112, kmeans=None, sift_features=None):\n",
    "\n",
    "            if not sift_features:\n",
    "                sift_features = self.extract_SIFT_descriptors(data)\n",
    "            \n",
    "            if not kmeans:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=42, n_init=1)\n",
    "                kmeans.fit(np.vstack(sift_features))\n",
    "            \n",
    "            # Create histograms for each image\n",
    "            for desc in sift_features:\n",
    "                if desc is not None and len(desc) > 0:\n",
    "\n",
    "                    # Predict cluster assignments for the reduced descriptors using the trained k-means model\n",
    "                    cluster_predictions = kmeans.predict(desc)\n",
    "\n",
    "                    # Create a histogram of cluster assignments (visual words)\n",
    "                    hist, _ = np.histogram(cluster_predictions, bins=np.arange(kmeans.n_clusters + 1), density=True)\n",
    "\n",
    "                    self.feature_vectors.append(hist)\n",
    "                else:\n",
    "                    # If no descriptors were found for this image, use an empty histogram\n",
    "                    self.feature_vectors.append(np.zeros(self.kmeans.n_clusters))\n",
    "            \n",
    "            return np.array(self.feature_vectors), kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class GaborExtractor:\n",
    "    def __init__(self):\n",
    "        self.filters = []\n",
    "        self.feature_vectors = []\n",
    "\n",
    "    def build_gabor_filters(self, orientations, frequencies, sigmas):\n",
    "        for θ in orientations:\n",
    "            for frequency, σ in zip(frequencies, sigmas):\n",
    "                λ = 1 / frequency  # Wavelength\n",
    "                γ = 0.5  # Spatial aspect ratio\n",
    "                kernel_size = int(3 * σ) if int(3 * σ) % 2 == 1 else int(3 * σ) + 1  # Ensure kernel size is odd\n",
    "                zero_kernel = cv2.getGaborKernel((kernel_size, kernel_size), σ, θ, λ, γ, 0, ktype=cv2.CV_32F)\n",
    "                neg_kernel = cv2.getGaborKernel((kernel_size, kernel_size), σ, θ, λ, γ, np.pi/2, ktype=cv2.CV_32F)\n",
    "                self.filters.append([zero_kernel, neg_kernel])\n",
    "\n",
    "    def extract_gabor_features(self, data, orientations, frequencies, sigmas):\n",
    "        self.build_gabor_filters(orientations, frequencies, sigmas)\n",
    "        print(\"Prepared Filters\")\n",
    "        num_images = len(data)\n",
    "        for i in range(num_images):\n",
    "            print(i)\n",
    "            feature_vector = np.zeros(2 * (1 + len(self.filters)), dtype=np.float32)\n",
    "            feature_vector_index = 0\n",
    "            image_responses = []\n",
    "            for zero_kernel, neg_kernel in self.filters:\n",
    "                zero_filtered = cv2.filter2D(data[i], cv2.CV_8U, zero_kernel)\n",
    "                neg_filtered = cv2.filter2D(data[i], cv2.CV_8U, neg_kernel)\n",
    "                E = np.sqrt(zero_filtered ** 2 + neg_filtered ** 2)\n",
    "                E = np.clip(E, -1e10, 1e10)  # Clamp the values to a reasonable range\n",
    "                image_responses.append(E)\n",
    "                E_mean = np.mean(E)\n",
    "                E_std = np.std(E)\n",
    "                feature_vector[feature_vector_index] = E_mean\n",
    "                feature_vector[feature_vector_index + 1] = E_std\n",
    "                feature_vector_index += 2\n",
    "\n",
    "            max_response = np.max(image_responses, axis=0)\n",
    "            max_response = np.clip(max_response, -1e10, 1e10)  # Clamp the values to a reasonable range\n",
    "            max_response_mean = np.mean(max_response)\n",
    "            max_response_std = np.std(max_response)\n",
    "            feature_vector[feature_vector_index] = max_response_mean\n",
    "            feature_vector[feature_vector_index + 1] = max_response_std\n",
    "            self.feature_vectors.append(feature_vector)\n",
    "\n",
    "        # Convert the list of feature vectors to a 2D numpy array\n",
    "        self.feature_vectors = np.array(self.feature_vectors)\n",
    "        return self.feature_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LawsExtractor:\n",
    "    def __init__(self):\n",
    "        self.filters = []\n",
    "        self.feature_vectors = []\n",
    "        L5 = np.array([1, 4, 6, 4, 1])\n",
    "        E5 = np.array([-1, -2, 0, 2, 1])\n",
    "        S5 = np.array([-1, 0, 2, 0, -1])\n",
    "        W5 = np.array([-1, 2, 0, -2, 1])\n",
    "        R5 = np.array([1, -4, 6, -4, 1])\n",
    "        self.masks = [L5, E5, S5, W5, R5]\n",
    "\n",
    "    def create_laws_kernels(self):\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                self.filters.append(np.outer(self.masks[i], self.masks[j]))\n",
    "    \n",
    "    def extract_laws_texture_energy_measures(self, data):\n",
    "        self.create_laws_kernels()\n",
    "        i = 0\n",
    "        for image in data:\n",
    "            print(i)\n",
    "            feature_vector = []\n",
    "            for kernel in self.filters:\n",
    "                filtered_image = np.abs(cv2.filter2D(image, -1, kernel))\n",
    "                energy = np.mean(filtered_image)\n",
    "                std = np.std(filtered_image)\n",
    "                feature_vector.extend([energy, std])\n",
    "            self.feature_vectors.append(feature_vector)\n",
    "            i += 1\n",
    "        self.feature_vectors = np.array(self.feature_vectors)\n",
    "        return self.feature_vectors\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    def __init__(self, kmeans=None, scaler=None, dropped_features=None):\n",
    "        self.kmeans = kmeans\n",
    "        self.scaler = scaler\n",
    "        self.dropped_features = dropped_features\n",
    "    \n",
    "    def load_features_from_file(self, filename):\n",
    "        data = np.genfromtxt(filename, delimiter=\",\")\n",
    "        X = data[:, :-1]\n",
    "        y = data[:, -1]\n",
    "\n",
    "        return (X, y)\n",
    "    \n",
    "    # Remove highly correlated features\n",
    "    def remove_highly_correlated_features(self, X, threshold=0.95):\n",
    "        corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "        X_reduced = np.delete(X, to_drop, axis=1)\n",
    "        return X_reduced, to_drop\n",
    "    \n",
    "    def extract_features(self, X=None):\n",
    "        orientations = [k * np.pi / 8 for k in range(1, 9)]\n",
    "        frequencies = np.linspace(0.2, 0.5, 3)\n",
    "        sigmas = np.linspace(3, 1, 3)\n",
    "        BoVW_extractor = BoVW()\n",
    "        gabor_extractor = GaborExtractor()\n",
    "        laws_extractor = LawsExtractor()\n",
    "        X_BoVW, _ = BoVW_extractor.extract_BoVW(data=X, kmeans=self.kmeans)\n",
    "        X_Gabor = gabor_extractor.extract_gabor_features(X, orientations, frequencies, sigmas)\n",
    "        X_Laws = laws_extractor.extract_laws_texture_energy_measures(X)\n",
    "        X = np.concatenate((X_BoVW, X_Gabor), axis=1)\n",
    "        X = np.concatenate((X, X_Laws), axis=1)\n",
    "        X = self.scaler.transform(X)\n",
    "        X = np.delete(X, self.dropped_features, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom transformers\n",
    "class ImagePreprocessorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        processed_images = []\n",
    "        for img in X:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            image_processor = ImagePreprocessor(img)\n",
    "            processed_img = image_processor.preprocess_image()\n",
    "            processed_images.append((processed_img > 127).astype(np.uint8))\n",
    "        return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, kmeans, scaler, dropped_features):\n",
    "        self.kmeans = kmeans\n",
    "        self.scaler = scaler\n",
    "        self.dropped_features = dropped_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        feature_extractor = FeatureExtraction(self.kmeans, self.scaler, self.dropped_features)\n",
    "        features = feature_extractor.extract_features(X)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the transformers\n",
    "image_preprocessor = ImagePreprocessorTransformer()\n",
    "feature_extractor = FeatureExtractorTransformer(kmeans, scaler, dropped_features)\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('image_preprocessor', image_preprocessor),\n",
    "    ('feature_extractor', feature_extractor),\n",
    "    ('classifier', svm_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_local.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'pipeline_local.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Abdelaal\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = joblib.load(\"pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
